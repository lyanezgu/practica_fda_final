---
title: "Práctica de Evaluación FAD - Métodos de Análisis de Datos"
author: "Isabela Ignacio, Luisa Yánez, Miguel García"
date: "14/01/2022"
output:
 html_document:
  code_folding: hide
  toc: yes
  toc_float: TRUE
  toc_depth: 3 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Introducción 

La práctica consiste en la elaboración y presentación de un informe de un proyecto de Ciencia de Datos, utilizando las técnicas aprendidas durante el curso, aplicadas a los datos seleccionados. 


## 1.1. Lenguaje de programación y herramienta de control de versiones utilizados

El grupo eligió trabajar en lenguage R (RStudio version 1.4.1717) y utilizar como herramienta de control de versiones Github. El proyecto "/practica_fd_final" fue creado por Luisa Yánez (usuario lyanezgu) y compartido con los restantes participantes del grupo Isabela Ignacio (usuario IsaPires1329) y Miguel García (usuario mgarciasanc2021).


## 1.2. Paquetes R utilizados

```{r librerias, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
library(formatR)
library(readr)
library(ggplot2)
library(GGally)
library(dplyr)
library(tidyr)
library(missForest)
library(VIM)
library(formattable)
library(usmap)
library(cowplot)
library(corrplot)
library(MASS)
library(ggfortify)
library(nortest)
library(car)
library(lmtest)
library(PerformanceAnalytics)
```


# 2. Conjunto de datos elegido

El conjunto de datos elegido por el grupo se llama "Hospital Charges in America" y incluye información que compara las tarifas de los servicios de hospitalizacón en diferentes estados de los EEUU para los 100 principales grupos de diagnósticos de enfermedades. 

**Link del data set:** <https://www.kaggle.com/dhirajnirne/hospital-charges-in-america>.


## 2.1. Carga de los datos

El conjunto de datos "Hospital Charges in America" contiene 12 columnas y 163.065 filas y lo obtenemos en formato .CSV. 
Inicialmente se han guardado los datos en un data frame llamado "hospital_charges" y se ha realizado un estudio inicial sobre su contenido utilizando la función head y summary.

```{r cargas datos, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
hospital_charges <- read_csv("notebooks/hospital-charges.csv")
head(hospital_charges)
summary(hospital_charges)
```


## 2.2. Definición de las variables que componen los datos de estudio

Empezando ya el análisis inicial del conjunto de datos que tenemos, vemos que las 12 variables que componen los datos pueden ser descritas como:

* **DRG Definition:** Grupo relativo a un diagnostico. 
Los grupos de diagnóstico relacionado (DRG) se utilizan para clasificar la gravedad de la enfermedad en las visitas hospitalarias de pacientes hospitalizados, el riesgo de mortalidad, el pronóstico, la dificultad del tratamiento, la necesidad de intervención y la intensidad de los recursos que necesitan. El sistema DRG fue desarrollado en la Universidad de Yale en la década de 1970 para la clasificación estadística de casos hospitalarios. Realmente la variable DRG es relativa al código y la descripción que identifican el MS-DRG. Los MS-DRG son un sistema de clasificación que agrupa condiciones clínicas similares (diagnósticos) y los procedimientos proporcionados por el hospital durante la estancia. El sistema de Medicare (Sistema de Seguridad Social en EEUU) los utiliza para determinar los reembolsos para hospitales, centros de enfermería especializada y hospicios. Una estadía en el hospital puede variar de un día a 100 días. Los MS-DRG más caros tienen las estadías promedio más largas. El establecimiento del cada DRG se establece según las condiciones clínicas del paciente, necesidad de cantidades similares de recursos para pacientes hospitalizados y sexo y edad del paciente. Para ello se utiliza el sistema de DRG llamado "Medicare Severity DRGs (MS-DRGs)" para reflejar en mejor manera la severidad de la enfermedad del paciente y su consumo de recursos para su recuperación. Para clasificar el nivel de severidad de un paciente dentro del sistema "MS-DRGs" hay códigos secundarios de diagnóstico:
    * MCC: Major Complication/Comorbidity -> El nivel más alto de severidad.
    * CC: Complication/Comorbidity -> El siguiente nivel de severidad.
    * Non-CC: Non-Complication/Comorbidity -> Este nivel no supone una gran severidad en la enfermedad ni un gran gasto de recursos;
    
* **Provider ID:** ID o número identificativo de referencia del hospital;

* **Provider Name:** Nombre del hospital;

* **Provider Street Address:** Dirección postal donde se ubica el hospital;

* **Provider City:** Ciudad donde se ubica el hospital;

* **Provider State:** Estado federal de EEUU donde se ubica el hospital;

* **Provider Zip Code:** Código postal donde se ubica el hospital;

* **Hospital Referral Region Description:** Delinación geográfica específica creada por la organización norteamericana "Dartmouth Atlas of Health Care", para estudiar los mercados vinculados al sector salud en EEUU;

* **Total Discharges:** Número de personas dadas de alta;

* **Average Covered Charges:** Gastos medios del hospital por los servicios cubiertos por la seguridad social para todas las altas del grupo relacionado con el diagnóstico. 
Por lo tanto cargo promedio según grupo de diagnóstico DRG establecido. Los pacientes que tienen características clínicas similares y costos de tratamiento similares se asignan a un Grupo de Diagnóstico Relacionado (DRG). El DRG está vinculado a un monto de pago fijo basado en el costo promedio del tratamiento de los pacientes del grupo.La asignación de DRG se basa en el diagnóstico del paciente, los procedimientos recibidos, la edad y otra información. Por lo tanto esta variable contiene el cargo promedio por cada DRG proporcionado por el hospital. Sus cargos promedio podrían ser más o menos dependiendo de las necesidades específicas de su paciente y los servicios prestados.E  sto es lo que el hospital cobra en la factura final del hospital y es equivalente al "sticker price". Este es en gran medida un número irrelevante, ya que no importa lo que cobren los diferentes hospitales, a todos se les pagará la misma cantidad de Medicare por cualquier DRG dado. Prácticamente nadie paga el "stiker price" en un hospital. Cuando un paciente ha sido admitido como hospitalizado en un hospital, ese hospital asigna un DRG cuando este paciente es dado de alta, basándolo en la atención que necesitaba durante su estadía en el hospital. Al hospital se le paga una cantidad fija por ese DRG, independientemente de cuánto dinero realmente gaste en su tratamiento. Si un hospital puede tratar a un paciente de forma efectiva por menos dinero del que Medicare paga por su DRG, entonces el hospital gana dinero con esa hospitalización. Si el hospital gasta más dinero cuidando del paciente de lo que Medicare le da para su DRG, entonces el hospital pierde dinero en esa hospitalización;

* **Average Medicare Payments:**Importe medio cubierto por la Seguridad Social de EEUU. Esto es lo que Medicare paga al hospital por ese DRG;

* **Average Total Payments:** Importe medio total a pagar por persona. 
Esto es lo que realmente se le paga al hospital e incluye lo que paga Medicare más los copagos que paga el paciente más cualquier cosa que pague el seguro secundario (seguro privado).


## 2.3. Definición de los objetivos

El objetivo final del proyecto es conseguir llegar a un modelo que permita recomendar cual es el hospital o grupo de hospitales óptimo que debe elegir un paciente enfermo en EEUU en base a la posible enfermedad que le van a diagnosticar, su localización geográfica y los costes que su caso clínico puede llegar a tener en base al sistema sanitario estadounidense.

Para esta primera entrega, el objetivo es realizar el tratamiento de datos adecuado y seleccionar las mejores variables que servirán para llegar al modelo de Machine Learning deseado. Se realizará de la misma manera un ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple en base a las variables que mejor expliquen los datos y evaluando si este se trata de un modelo correcto para nuestros datos o no.


## 2.4. Limpieza inicial del conjunto de datos

### 2.4.1. Cambio de nombres de las columnas

Se ha decidido realizar un cambio en el nombre de las variables que aparecen en las columnas de los datos para así seguir un mismo patrón y a la vez evitar tener espacios que nos pueden llegar a dar problemas a futuro.

```{r cambiar columnas 1, include=TRUE, message=FALSE, warning = FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
names(hospital_charges) <- c('drg_def', 'prov_id', 'prov_name', 'prov_address', 'prov_city', 'prov_state', 'prov_zip','hospital_ref', 'total_discharges','mean_covered_charges', 'mean_total_payments', 'mean_medicare_payments')
                    
head(hospital_charges)
```


### 2.4.2. Cambio de tipo de variable

Se ha decidido eliminar el símbolo de moneda de dólar de las últimas tres columnas (mean_covered_charges, mean_total_payments y mean_medicare_payments), transformando las columnas a tipo numérico. Las columnas prov_zip y prov_id han sido transformadas en factores.

```{r cambiar dolares, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
hospital_charges$mean_covered_charges = as.numeric(gsub("\\$","",hospital_charges$mean_covered_charges))

hospital_charges$mean_total_payments = as.numeric(gsub("\\$","",hospital_charges$mean_total_payments))

hospital_charges$mean_medicare_payments = as.numeric(gsub("\\$","",hospital_charges$mean_medicare_payments))

hospital_charges$prov_zip = as.factor(hospital_charges$prov_zip)

hospital_charges$prov_id = as.factor(hospital_charges$prov_id)

head(hospital_charges)

str(hospital_charges)
```


# 3. Añadiendo datos faltantes al data set

A través de la función summary empezamos comprobando que no hay datos faltantes en el data set. Por ello el grupo ha tenido que añadirlos manualmente para tratar de aproximarnos a un caso más real donde lo normal es encontrarlos y tener que lidiar con ellos. Los datos faltantes han sido imputados exclusivamente en las columnas que no creemos que no van a servir de análisis principal para este estudio (total_discharges y mean_covered_charges), para así intentar que la predicción que hagamos sea lo más precisa posible.

Utilizamos la librería missForest y generamos una semilla para que el resultado sea siempre el mismo.

```{r df, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
hospital_charges
set.seed(101)
hospital_charges <-bind_cols(hospital_charges[c(1,2,3,4,5,6,7,8,11,12)],
                             missForest::prodNA(hospital_charges[c(-1,-2,-3,-4,-5,-6,-7,-8,-11,-12)],noNA=0.1))
hospital_charges
```

Haciendo uso de la librería VIM, analizamos un poco la estructura que tienen nuestros datos faltantes dentro de nuestro data set para ver y entender como se distribuyen. 

Se puede comprobar que la proporción de datos faltantes en estas variables es de aproximadamente 10% y hay 1.622 filas en que las dos variables son faltantes.

```{r dfdos, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(aggr(hospital_charges,numbers=T,sortVar=T))

```


# 4. Partición del conjunto de datos: data set training y data set test

Una vez vistos por encima la estructura general de los datos y habiendo añadido los datos faltantes que nos hacian falta, pasamos a dividir el conjunto de datos en dos para diferenciar los que usaremos de entrenamiento de los que usaremos de test (viendo la cantidad de datos de la que disponemos, la distribución elegida ha sido: 20% test y 80% training). Establecemos una semilla que nos guarde de forma permanente la división que hacemos para que la división de los datos sea siempre la misma.

Guardamos además la partición de datos de test para ser utilizada a futuro para la validación del modelo final y pasamos a trabajar de aquí en adelante con la partición de training.

```{r p, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(101)
sample <- sample.int(n=nrow(hospital_charges), size=floor(.80*nrow(hospital_charges)), replace = F)
train <- hospital_charges[sample,]
test <- hospital_charges[-sample,]

train
test
```


# 5. Detección, tratamiento e imputación de datos faltantes

Para la imputación de datos faltantes en las columnas mean_covered_charges y total_discharges, reemplazados todos sus NAs según los valores medios de las mismas. 
Con la función summary se comprueba que ya no hay más datos faltantes en el data set train.

```{r imputacion, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train$mean_covered_charges[is.na(train$mean_covered_charges)]<-mean(train$mean_covered_charges,na.rm = TRUE)

train$total_discharges[is.na(train$total_discharges)]<-mean(train$total_discharges,na.rm = TRUE)

summary(train)
```


# 6. EDA - Análisis exploratorio de datos

Una vez entendidas las variables de nuestro conjunto de datos y teniendo claro nuestros objetivos de estudio, pasamos a la parte de análisis en profundidad de nuestros datos, para tratar de entenderlos y ver como se relacionan unas variables con otras.

## 6.1. Transformaciones de variables cuantitativas y procesado de variables cualitativas

### 6.1.1. División de la columna drg_def

Primero de todo realizamos una división de la columna "drg_ref". Separamos la columna en dos, diferenciando entre código de la enfermedad y descripción de la enfermedad. Nos servirá a futuro para simplificar el análisis y visualización de los datos de interés en graficos y tablas.

```{r, message=FALSE, warning=FALSE, include=TRUE}
train <-train %>% 
  separate(data = ., col = drg_def, 
       into = c("codigo_enf", "desc_enf"), sep = "-")

train$codigo_enf <- as.factor(train$codigo_enf)

train
```


### 6.1.2. Creando columna nueva relativa a los copagos que deben realizar los pacientes: mean_total_payments - mean_medicare_payments

El grupo ha decidido crear una nueva variable representativa del valor de los copagos que debe realizar el paciente o su seguro privado (en caso de contar con uno), para completar (junto a lo que cubre el Estado con el Medicare) el coste total de la intervención hospitalaria (el total que realmente cobra el hospital por la intervención).


```{r nueva variable, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train <- train %>% mutate(copagos = mean_total_payments - mean_medicare_payments)
train
```

### 6.1.3. Creando columna nueva relativa a la tasa de cobertura de la Seguridad Social estadounidense: mean_medicare_payments/mean_total_payments

Además de la variable copago, hemos creado una nueva variable representativa de la tasa de cobertura que ofrece el sistema de salud de la Seguridad Social americana según el hospital, el grupo de diagnóstico y la gravedad del paciente. Nos ayudamos para ello de la librería formattable, obteniendo resultados en forma de porcentaje de cobertura sobre el total a pagar al hospital.

```{r nueva variabledos,  include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train <- train %>% mutate(cobertura = percent(mean_medicare_payments/mean_total_payments))

train
```

### 6.1.4. Creando columna nueva para uso en variables categóricas: Media por Estado según mean_total_payments = mean_total_state

Como tenemos dos variables categóricas (Estado y grupo de enfermedad) que queremos comprobar su efecto en nuestro modelo de regresión lineal múltiple, tenemos que crear variables dummies que serán variables creadas para cada uno de los niveles del predictor categórico y que pueden tomar valores de 0 o 1.

Inicialmente hemos creado una nueva columna mean_total_payments agrupada por state (es decir, la media de total_payments por Estado) para que así, Estados iguales tengan el mismo valor cuantitativo en esta variable. 

```{r mean total state, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train <- train %>% group_by(prov_state) %>% 
  mutate(mean_total_state=mean(mean_total_payments))

train
```

### 6.1.5. Creando columna nueva para uso en variables categóricas: Media por enfermedad según mean_total_payments = mean_total_enf

Hacemos exactamente lo mismo para la variable enfermedad. Creamos una nueva columna mean_total_payments agrupada por código de enfermedad (es decir, la media de total_payments por tipo de enfermedad DRG) para que así, enfermedades DRG iguales tengan el mismo valor cuantitativo en esta variable.

```{r mean total enf,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train <- train %>% group_by(codigo_enf) %>% 
  mutate(mean_total_enf=mean(mean_total_payments))

train
```


### 6.1.6. Variable categórica dummy: categoria_state -> niveles alto, medio y bajo

Una vez que hemos creado nuestras nuevas colunmas cuantitativas y para reducir los niveles del predictor categóricos a 3, creamos una segunda nueva variable agrupando los costes por Estados (51 estados) por 3 niveles High, Mid y Low según la variable "mean_total_state" recientemente creada. 

Para estabelecer los limites de la partición por categorias nos hemos basado en los valores numéricos obtenidos con la variable creada de "mean_total_state" y en un análisis visual del mapa de EEUU donde podemos distinguir a grandes rasgos 3 niveles por colores.

```{r test mapa 3, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
region_geog_3 <- train %>% group_by(prov_state) %>% summarise (mean_total_cost = mean(mean_total_state))

names(statepop) <- c('fips','prov_state','full','pop_2015') 

statepop4 <- statepop %>% left_join(region_geog_3, by='prov_state') 

plot_usmap(data = statepop4, values = "mean_total_cost", color = "white") + 
  scale_fill_continuous(low='green', high ='red',name = "Media Costes por Estado", label = scales::dollar) + 
  theme(legend.position = "right")
```

Finalmente se opta por dividir a los 3 grupos de Estados de la siguiente manera:

* **High o de coste alto:** para los Estados con un coste total en media igual o mayor a 12.000 dólares (colores rojos y anaranjados)
* **Mid o de coste medio:** para los Estados con un coste total en media igual o mayor a 8.500 dólares y menor a 12.000 dólares (colores verdes apagados o poco intensos)
* **Low o coste bajo:** para los Estados con un coste total en media inferior a 8.500 dólares (colores verdes intensos)

```{r grupo estado, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}

train<-train %>%
    mutate(categoria_state = case_when(mean_total_state >= 12000  ~ 'High',
                                  mean_total_state >= 8500 ~ 'Mid',
                                  TRUE ~ 'Low'))
train
 
ggplot(train)+geom_bar(aes(x=categoria_state, fill = categoria_state)) + theme(legend.position ="none")+ggtitle("Frecuencia por categoria creada para Estados - Low, Mid y High")
```

Observamos como la gran mayoría de Estados se situan en la categoría de coste total medio, siendo más raro encontrar Estados de coste total bajo o alto.

```{r dummys, include=FALSE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
res <- model.matrix(~categoria_state, data = train)
head(res[, -1])
```

### 6.1.7. Variable categórica dummy: categoria_enf -> niveles alto, medio y bajo

La misma lógica del apartado anterior ha sido utilizada para agrupar los grupos de enfermedad (100 grupos de enfermedad) en apenas Low, Mid y High según la variable "mean_total_enf".

Para estabelecer los limites de la partición por categorias nos hemos basado en los valores numéricos obtenidos con la variable creada de "mean_total_enf" y en un análisis visual con un gráfico donde podemos distinguir a grandes rasgos 3 niveles por grados de color y longitud de las barras.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60), fig.width=10, fig.height=7}
ggplot(data=train, aes(x=codigo_enf, y=mean_total_enf, fill=mean_total_enf)) +
    geom_bar(colour="black", stat="identity",
             position=position_dodge(),
             size=.3) +                        
    xlab("codigo_enf") + ylab("mean_total_enf") + 
    ggtitle("Coste medio según tipo de enfermedad") +     
    theme_bw() + 
    theme(axis.text=element_text(size=7, angle = 90)) + 
    scale_y_continuous(labels = scales::dollar)
```

Finalmente se opta por dividir a los 3 grupos de Enfermedades de la siguiente manera:

* **High o de coste alto:** para las Enfermedades con un coste total en media igual o mayor a 15.000 dólares (colores rojos y anaranjados)
* **Mid o de coste medio:** para las Enfermedades con un coste total en media igual o mayor a 5.000 dólares y menor a 15.000 dólares (colores verdes apagados o poco intensos)
* **Low o coste bajo:** para las Enfermedades con un coste total en media inferior a 5.000 dólares (colores verdes intensos)

```{r grupo enf, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train<-train %>%
    mutate(categoria_enf = case_when(mean_total_enf >= 15000 ~ 'High',
                                  mean_total_enf >= 5000 ~ 'Mid',
                                  TRUE ~ 'Low'))
train

ggplot(train)+geom_bar(aes(x=categoria_enf, fill = categoria_enf)) + theme(legend.position ="none")+ggtitle("Frecuencia por categoria creada para Enfermedades - Low, Mid y High")
```

Observamos de nuevo como la gran mayoría de Enfermedades se situan en la categoría de coste total medio, siendo más raro encontrar Enfermedades de coste total bajo o alto.

```{r}
res2 <- model.matrix(~categoria_enf, data = train)
head(res2[, -1])
```

## 6.2. Análisis exhaustivo de los datos críticos para el estudio

### 6.2.1. Gráficos de mapa de EEUU: valor de los Copagos y Costes Médicos por Estado y su comparativa

Por un lado, con la ayuda de la libreria "usmap", hemos creado primero un mapa para visualmente identificar como se distribuyen los valores de copagos en los diferentes Estados de EEUU.

```{r test mapa, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
region_geog <- train %>% group_by(prov_state) %>% summarise (mean_total_price = mean(copagos))
names(statepop) <- c('fips','prov_state','full','pop_2015') 

statepop2 <- statepop %>% left_join(region_geog, by='prov_state') 

plot_usmap(data = statepop2, values = "mean_total_price", color = "white") + 
  scale_fill_continuous(low='light blue', high ='dark blue',name = "Media Copagos", label = scales::dollar) + 
  theme(legend.position = "right")
```

Los Estados americanos más caros para el paciente son Wyoming (copagos medio de 1.983 dólares), Utah (copagos medio de 1.927 dólares) y Hawái (copagos medio de 1.851 dólares) 

Wyoming es el estado menos poblado de EEUU (dos tercios del territorio cubiertos por sierras y montañas), los componentes de su economia difieren significativamente de los otros Estados (minería y turismo) y el gobierno es dueño de 50% de sus tierras.


Por otro lado, y usando la misma libreria "usmap", creamos un nuevo mapa para visualmente identificar como se distribuyen los valores de total_payments o costes totales que cobra el hospital en los diferentes Estados de EEUU.

```{r test mapa 2, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
region_geog_2 <- train %>% group_by(prov_state) %>% summarise (mean_total_cost = mean(mean_total_payments))

names(statepop) <- c('fips','prov_state','full','pop_2015') 


statepop3 <- statepop %>% left_join(region_geog_2, by='prov_state') 

plot_usmap(data = statepop3, values = "mean_total_cost", color = "white") + 
  scale_fill_continuous(low='light green', high ='dark green',name = "Media Costes Totales", label = scales::dollar) + 
  theme(legend.position = "right")
```

En este caso vemos que los Estados americanos con los costes médios totales más elevados son Alaska (media coste total de 14.928 dólares), DC - Washington (media coste total de 13.382 dólares) y Hawái (media coste total de 12.996 dólares).


Comparando los dos gráficos de mapa se puede concluir que Estados como Hawái y Alaska tienen un coste médio total de tratamiento alto, así como un copago alto para los pacientes. Wyoming, el Estado con el copago caro para el paciente, es también el quinto estado con tratamiento hospitalar total medio más caro. Destacan además Estados como California y DC - Washington, los cuales si muestran un coste total alto en media, pero tienen copagos relativamente pequeños para el paciente, suponiendo esto unas tasas de cobertura alta del Medicare de la Seguridad Social de EEUU. Podemos entonces ver que no todos los Estados siguen el mismo patrón de relación entre el coste total y los copagos de los pacientes.


### 6.2.2. Top 10 enfermedades más comunes detectadas

Creamos un grafico de barras para visualizar las 10 enfermedades más comunes de nuestro data set.


```{r top 10 comunes, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
d2 <- train %>%
group_by(codigo_enf) %>% summarise(n = n()) %>% arrange(desc(n)) %>% mutate(codigo_enf=factor(codigo_enf, codigo_enf))

top_10_comunes <- head(d2,10)

train %>%
  filter(codigo_enf %in% top_10_comunes$codigo_enf) %>%
  mutate(codigo_enf = factor(codigo_enf, levels = levels(top_10_comunes$codigo_enf))) %>%
  ggplot(aes(x = codigo_enf, fill=desc_enf)) + geom_bar() + 
theme_bw(base_size=9) + xlab("Código enfermedad") + 
    ylab("Frecuencia") +
    ggtitle("10 enfermedadas más comunes")
```

El grupo DRG de mayor frecuencia es "194 - Pneumonia y Pleuresía con complicaciones/patolog
ias previas" (nivel medio de severidad) con 2.424 casos. En segundo y tercer lugar tenemos las "690 - Infecciones de las vías urinarias" (2.400 casos) y "392 -Esofagitis, Gastroenteritis y Enfermedades digestivas con " (2.368 casos) con o sin complicaciones.


### 6.2.3. Top 10 enfermedades más caras 

Creamos un grafico de barras para visualizar las 10 enfermedades más caras de nuestro data set.

```{r 10 mas caras, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
d3 <- train %>%
  group_by(codigo_enf) %>% summarise(mean=mean(mean_total_payments)) %>% arrange(desc(mean))

top_10_caras <- head(d3,10)


ggplot(data=top_10_caras, mapping = aes(x = reorder(codigo_enf,-mean),mean)) + geom_bar(stat = "identity", aes(fill=mean)) + theme_bw(base_size=9) + ylab("Media Total Payments") + xlab("Codigo enfermedad") + ggtitle("10 enfermedadas más caras") + scale_y_continuous(label = scales::dollar) + scale_fill_gradient(low="light blue", high="dodgerblue4")
```

El grupo DRG más caro es "870 - Septicemia y sepsis grave con periodo de hospitalización superior a 96 horas". Una septicemia occure cuando el sistema inmunitario se descontrola y ataca a sus proprios órganocs y tejidos. Es la complicación de una infección, siendo una urgencia médica que requiere tratamiento inmediato. El coste media del tratamiento en los EEUU es de 44.467 dólares. 

El segundo y tercer grupo DRG más caros son las "853 - Infecciones y enfermedades parasitarias" (coste médio de 40.296 dólares) y "207- Enfermedades respiratorias que requieren ventilación respiratória por más de 96 horas consecutivas (coste médio de 38372.14 dólares).	

### 6.2.4. Gráfico de calor - ratio de cobertura por Estado para las 10 enfermedades más caras

Creamos un grafico de calor para visualizar el ratio de cobertura pro Estado para las 10 enfermedades más caras de nuestro data set.

```{r calor ratio cobertura, minclude=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
test <- top_10_caras %>% inner_join(train)

ggplot(test, aes(codigo_enf,prov_state, fill=cobertura))+geom_tile() + theme_bw(base_size=7) + scale_fill_gradient(low = "white", high = "dodgerblue4")
```

De manera general se puede decir que la tasa de cobertura de las top 10 enfermedades más caras es, en todos los estados de Estados Unidos, superior a 80% (colores morado escuro predominante en casi todo el gráfico).

La tasa de cobertura para la enfermedad Septicemia es en media, para todos los estados, de 95%, siendo entonces la enfermedad más cara para el sistema público, pero con gran cobertura y pocos copagos al paciente. Lo mismo se puede observar para las Enfermedades Parasitárias (94%) y Enfermedades Respiratória (93%).

En Wyoming, el Estado donde se pagan las mayores cifras de copagos, no han sido registrados casos de Septicemia o Enfermedades Respiratórias, mientras la tasa de cobertura para Enfermedades Parasitárias es de 82%.


### 6.2.5. Correlación entre variables

#### 6.2.5.1. Correlación: mean_total_payments y mean_medicare_payments

Queremos analizar si se puede afirmar estadisticamente que hay correlación positiva entre las variables mean_total_payments y mean_medicare_payments.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x=train$mean_total_payments, y=train$mean_medicare_payments)
```

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train %>% ggplot(aes(mean_total_payments, mean_medicare_payments)) + 
  geom_point(alpha=0.2, colour="green") + 
  geom_smooth(formula= 'y ~ x',method = 'lm') + 
  labs(title='Relación entre variables total payments y medicare payments', 
       x='mean total payments',
       y='mean medicare payments')
```

A través de la gráfica y de la función cor (valor 0.99 aproximadamente), afirmamos que estás dos variables se correlacionan positivamente en un grado muy alto. Se aprecia que a nivel general en la gran mayoría de casos, cuando aumenta el coste (sube la variable "mean total payments"), aumenta la cobertura del Medicare (sube también la variable "mean medicare payments").

#### 6.2.5.2. Correlación: mean_total_payments y copagos

Queremos analizar si se puede afirmar estadisticamente que hay correlación positiva entre las variables mean_total_payments y copagos.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x=train$mean_total_payments, y=train$copagos)
```

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train %>% ggplot(aes(mean_total_payments, copagos)) + 
  geom_point(alpha=0.2, colour="green") + 
  geom_smooth(formula= 'y ~ x',method = 'lm') + 
  labs(title='Relación entre variables total payments y copagos', 
       x='mean total payments',
       y='copagos')
```

A través de la gráfica y de la función cor (valor 0.38 aproximadamente), afirmamos que estás dos variables se correlacionan positivamente a un nivel medio-bajo. No se puede afirmar que en la gran mayoría de casos, cuando aumenta el coste de la enfermedad, aumenta en la misma medida el copago que debe pagar el paciente.

#### 6.2.5.3. Correlación: mean_medicare_payments y copagos

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x=train$mean_medicare_payments, y=train$copagos)
```

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train %>% ggplot(aes(mean_medicare_payments, copagos)) + 
  geom_point(alpha=0.2, colour="green") + 
  geom_smooth(formula= 'y ~ x',method = 'lm') + 
  labs(title='Relación entre variables medicare payments y copagos', 
       x='mean_medicare_payments',
       y='copagos')
```

A través de la gráfica y de la función cor (valor 0.24 aproximadamente), afirmamos que estás dos variables se correlacionan positivamente a un nivel medio-bajo. No se puede afirmar que en la gran mayoría de casos, cuando aumenta la cobertura de la enfermedad por parte de la seguridad social, aumenta en la misma medida el copago que debe pagar el paciente. La tasa de cobertura no es igual siempre, sino que varía entre los diferentes tipos de enfermedad y por ello los copagos no son siempre iguales en proporción.

#### 6.2.5.4. Correlación: cobertura y copagos

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x=train$cobertura, y=train$copagos)
```

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train %>% ggplot(aes(cobertura, copagos)) + 
  geom_point(alpha=0.2, colour="green") + 
  geom_smooth(formula= 'y ~ x',method = 'lm') + 
  labs(title='Relación entre variables cobertura y copagos', 
       x='cobertura',
       y='copagos')
```

A través de la gráfica y de la función cor (valor -0.43 aproximadamente), afirmamos que estás dos variables se correlacionan negativamente a un nivel medio-bajo. No se puede afirmar que en la gran mayoría de casos, cuando aumenta la tasa de cobertura de la enfermedad por parte de la seguridad social, disminuya en la misma medida el copago que debe pagar el paciente. La tasa de cobertura no es igual siempre, sino que varía entre los diferentes tipos de enfermedad y por ello los copagos no son siempre iguales en proporción. 

Puede haber enfermedades caras con porcetajes de cobertura muy altos, pero que por el hecho de ser caras, sus copagos siguen siendo alto igualmente en términos absolutos. O se puede dar el caso de enfermedades no tan caras, pero con tasas de cobertura de la seguridad social muy bajas, que terminan traduciéndose en copagos muy altos para el paciente en términos absolutos y relativos.

### 6.2.6. Análisis de la distribución de las variables

#### 6.2.6.1. Distribución variable mean_total_payments

Queremos verificar si la variable **"mean_total_payments"** sigue una distribución normal.
```{r total sin log, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_total_payments<100000 ) %>%
  ggplot(aes(x=mean_total_payments))+ geom_histogram(color="red", fill = "red") + ggtitle("Distribuición normal - Mean Total Payments")
```

Podemos ver que los valores están muy sesgados. Sería conveniente transformar esta variable para que la distribución de sus valores fuese más homogénea. Este resultado se consigue aplicando una transformación logarítmica.


```{r total con log , include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_total_payments<100000 ) %>%
  ggplot(aes(x=log10(mean_total_payments)))+ geom_histogram(color="red", fill = "red") + ggtitle("Distribuición normal - Log Mean Total Payments")
```

#### 6.2.6.2. Distribución variable mean_medicare_payments

Ahora queremos ver si la variable **"mean_medicare_payments"** sigue una distribución normal.

```{r medicare sin log,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_medicare_payments<100000) %>%
  ggplot(aes(x=mean_medicare_payments))+ geom_histogram(color="blue", fill = "blue") + ggtitle("Distribuición normal - Mean Medicare Payments")
```

Analizamos la normalidad de la misma variable, pero ahora otra vez utilizando logaritmos.

```{r medicare con log,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_medicare_payments<100000) %>%
  ggplot(aes(x=log10(mean_medicare_payments)))+ geom_histogram(color="blue", fill = "blue")+ggtitle("Distribuición normal - Log Mean Medicare Payments")
```

#### 6.2.6.3. Distribución variable copagos

Analizamos por fin si la variable **"copagos"** sigue una distribución normal.

```{r copago sin log,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_medicare_payments<100000) %>%
  ggplot(aes(x=copagos))+ geom_histogram(color = "orange", fill = "orange") + ggtitle("Distribuición normal - Copagos") 
```

Analizamos la normalidad de la misma variable, utilizando otra vez logaritmos.

```{r copagos con log,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_medicare_payments<100000) %>%
  ggplot(aes(x=log10(copagos)))+ geom_histogram(color = "orange", fill = "orange") + ggtitle("Distribuición normal - Log Copagos")
```

#### 6.2.6.4. Distribución variable cobertura

Analizamos por fin si la variable **"cobertura"** sigue una distribución normal.

```{r cobertura sin log,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_medicare_payments<100000 ) %>%
  ggplot(aes(x=cobertura))+ geom_histogram(color = "green", fill = "green") + ggtitle("Distribuición normal - Cobertura") 
```

Analizamos la normalidad de la misma variable, utilizando otra vez logaritmos.

```{r cobertura con log,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train%>%
  filter(mean_medicare_payments<100000) %>%
  ggplot(aes(x=log10(cobertura)))+ geom_histogram(color = "green", fill = "green") + ggtitle("Distribuición normal - Log Cobertura")
```

Graficamente podemos decir que las tres primeras curvas de distribución se asemejan a una distribuición normal ligeramente concentrada a la izquierda (con valores de mayor coste,  más raros, infrecuentes y extremos, ubicados a la derecha de la distribución). En el caso de la última distribución mostrada, se ve que pasa justo lo contrario, la mayor parte de valores se ubican a la derecha de la distribución (entre tasas de cobertura médica de entre un 50% y un 100%).


### 6.2.7. Boxplot - análisis de la variables de relevancia y de los atípicos observados

Creamos un sub data set solo con las variables numéricas para analizar si tienen valores atípicos.

```{r variables numericas,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train_num <- Filter(is.numeric, train)
train_num
```
 
#### 6.2.7.1. Boxplot variable mean_total_payments
 
```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
p1 <- ggplot (train_num, aes(y= train_num$mean_total_payments)) + geom_boxplot(fill = "red") + scale_y_continuous(name = "dólares", labels = scales::dollar) + xlab("mean_total_payments") + ggtitle("Boxplot: mean_total_payments")

p11 <- ggplot (train_num, aes(y= log10(train_num$mean_total_payments))) + geom_boxplot(fill = "red") + scale_y_continuous(name = " Log dólares", labels = scales::dollar) + xlab("mean_total_payments") + ggtitle("Boxplot: Log mean_total_payments")

plot_grid(p1, p11)
mean(train_num$mean_total_payments)
```

#### 6.2.7.2. Boxplot variable mean_medicare_payments

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
p2 <- ggplot (train_num, aes(y=train_num$mean_medicare_payments)) + geom_boxplot(fill = "blue") + scale_y_continuous(name = "dólares", labels = scales::dollar) + xlab("mean_medicare_payments") + ggtitle("Boxplot: mean_medicare_payments")

p22 <- ggplot (train_num, aes(y= log10(train_num$mean_medicare_payments))) + geom_boxplot(fill = "blue") + scale_y_continuous(name = "Log dólares", labels = scales::dollar) + xlab("mean_medicare_payments") + ggtitle("Boxplot: Log mean_medicare_payments")

plot_grid(p2, p22)
mean(train_num$mean_medicare_payments)
```

#### 6.2.7.3. Boxplot variable copagos

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
p3 <- ggplot (train_num, aes(y=train_num$copagos)) + geom_boxplot(fill = "yellow") + scale_y_continuous(name = "dólares", labels = scales::dollar) + xlab("copagos") + ggtitle("Boxplot: copagos")

p33 <- ggplot (train_num, aes(y=log10(train_num$copagos))) + geom_boxplot(fill = "yellow") + scale_y_continuous(name = "Log dólares", labels = scales::dollar) + xlab("copagos") + ggtitle("Boxplot: Log copagos")

plot_grid(p3, p33)
mean(train_num$copagos)
```

#### 6.2.7.4. Boxplot variable cobertura

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
p4 <- ggplot (train_num, aes(y=train_num$cobertura)) + geom_boxplot(fill = "green") + scale_y_continuous(name = "% cobertura") + xlab("cobertura") + ggtitle("Boxplot: cobertura")

p4
mean(train_num$cobertura)
```


### 6.2.8. Análisis de correlación entre variables númericas

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
res <- cor(train_num)
round(res, 2)

corrplot(res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```
Se observa una correlación positiva en casi todos los casos, excepto para copagos y cobertura.


```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ggplot(data = train, mapping=aes(x = categoria_state, y = log10(copagos), color=categoria_state)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")
```


```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ggplot(data = train, mapping=aes(x = categoria_enf, y = log10(copagos), color=categoria_enf)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")
```


# 7. Regresion lineal multiple

## 7.1. Ajuste del modelo de regresión

Ajustamos un modelo de regresión lineal mútiple con el que vamos a predecir el valor de la variable copagos a partir de las siguientes variables independientes(categoria_state, categoria_enf,cobertura, mean_covered_charges y total_discharges).

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
modelo= lm(copagos~categoria_state+categoria_enf+cobertura
           +mean_covered_charges+total_discharges,data=train)

summary(modelo)
```


## 7.2. Seleccion de variables para modelo de regresión

Para la selección de variables se utiliza el método de la selección automática por pasos.

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
empty.model <- lm(copagos ~ 1, data=train)
horizonte <- formula(copagos~categoria_state+categoria_enf+cobertura
           +mean_covered_charges+total_discharges)
#metodo de selección por pasos e indica las variables que son significativas
seleccion=stepAIC(empty.model,direction = c("both"),trace=FALSE,scope = horizonte)
seleccion$anova
```

Vemos la información del modelo elegido como "mejor"
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(seleccion)
```

Nos quedamos con el modelo seleccionado como el mejor para la regresión según el método utilizado anteriormente.
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
mejor_modelo=lm(copagos~categoria_state+categoria_enf+cobertura
           +mean_covered_charges+total_discharges,data=train)

summary(mejor_modelo)
```

### 7.2.1. Intervalos de confianza

Determinamos los intervalos de confianza para las observaciones de nuestros datos.
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
intervalos = predict(mejor_modelo,interval = "confidence",level = 0.95)
head(intervalos)
```

###  7.2.2. Tabla anova

La tabla anova nos muestra la significación de la regresión, en nuestro caso se puede ver en los resultados que la variable total_discharge no es significativa para el modelo ya que tiene un p_valor > 0.05.
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
anova=aov(mejor_modelo)
summary(anova)
```


## 7.3. Diagnosis del modelo según el cumplimiento de los siguientes supuestos

### 7.3.1. Linealidad de los residuos

Como se puede ver en el resultado la media de los residuos es casi cero por lo que tendríamos linealidad.
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
mean(mejor_modelo$residuals)
```

También podemos comprobar graficamente la linealidad y como se puede ver en la gráfica la línea roja está muy cerca de la línea ideal unicamente tiene una desviación en la cola derecha  y pueden ser por los outliers..

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#forma grafico 1
plot(mejor_modelo,1)
#forma grafico 2 que te muestra lo mismo 
autoplot(mejor_modelo,1)
```

En el gráfico de Residuos vs. Ajustes se observa que la media de los residuos es cercana a cero, luego la linealidad del modelo no se viola.

### 7.3.2. Normalidad de los residuos

Primero se comprueba la normalidad de los residuos, pero al usar Shapiro test solo permite usar las 5000 primeras muestras de los residuos, así que también usamos Anderson-Darling para comparar resultados. Como se comprueba más adelante el p_value < 0.05, se rechaza la hipotesis nula de que los residuos siguen una distribución normal.

* Shapiro:
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#muestras_residuos=resid(mejor_modelo)
#obtengo la ditribucion de los residuos estandarizados
muestras_residuos1=studres(mejor_modelo)
residual_norm=shapiro.test(muestras_residuos1[0:5000])
residual_norm
```

* Anderson-Darling:
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#install.packages('nortest')
residual_anderson=ad.test(muestras_residuos1)
residual_anderson
```

Este supuesto de normalidad de los residuos también se puede comprobar graficamente y como se ve en la gráfica nuestros datos se separan en las colas de la línea principal y eso nos  puede indicar que los residuos no siguen una diatribución normal.

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Estas tres graficas te muestran lo mismo
plot(mejor_modelo,2)

autoplot(mejor_modelo,2)

hist(muestras_residuos1, freq=FALSE,main="Distribución de los residuos estandarizados")
xfit<-seq(min(muestras_residuos1),max(muestras_residuos1),length=40)
yfit<-dnorm(xfit)
lines(xfit,yfit)
```

Con el Q-Q plot vemos que los residuos no siguen una distribución normal en las colas. Por tanto, no se puede asumir que los estimadores de los coeficientes tengan una distribución normal.

### 7.3.3. Homocedasticidad

Vamos a comprobar la homocedasticidad (que los residuos tengan una varianza constante).

Como podemos ver en los resultados p_value < 0.05 por tanto se rechaza la hipotesis nula y esto indica que la varianza no es constante para este modelo de regresion lineal(esto es un problema). Podemos concluir que este modelo matemático no es adecuado.

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#https://fhernanb.github.io/libro_regresion/homo.html
#otra prueba para comprobar homocedasticidad
ncvTest(mejor_modelo)
```

También podemos comprobar gráficamente la hocedasticidad, sería bueno que la línea roja sea lo más recta/horizontal posible.

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#rechazamos la hipotesis nula que la varianza de los errores ees constante
plot(mejor_modelo,3)

autoplot(mejor_modelo,3)
```

Hay claro patrón de embudo, lo que indica que se viola el principio de homocedasticidad del modelo. Es decir, la varianza de los residuos no es constante y el ajuste del modelo no es adecuado. También se señalan algunos puntos candidatos a ser outliers

### 7.3.4. Independencia de los residuos

Como se puede ver en los resultados el p_value > 0.05 por lo que aceptamos la Ho de que hay independencia.
```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#medimos independencia entre los residuos
#entonces no rechazamos la  hipotesis nula y podemos asumir que los residuos no presentan autcorrelacion
dwtest(mejor_modelo)
```

Se puede comprobar la independencia de los residuos gráficamente y como se observa no se ven patrónes extraños y esto nos puede indicar que hay independencia en los residuos y que estos no presentan autocorrelación.

```{r,include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot(mejor_modelo$resid)

acf(mejor_modelo$residuals)
```


# 8. Conclusiones generales del estudio