---
title: "Práctica de Evaluación FAD - Métodos de Análisis de Datos"
author: "Isabela Ignacio, Luisa Yánez, Miguel García"
date: "18/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Introducción 

La práctica consiste en la elaboración y presentación de un informe de un proyecto de Ciencia de Datos, utilizando las técnicas aprendidas durante el curso, aplicadas a los datos seleccionados. 


# 1. Uso de herramienta de control de versiones

El grupo eligió trabajar en lenguage R (RStudio version 1.4.1717) y utilizar como herramienta de control de versiones Github. El proyecto "/practica_fd_final" fue creado por Luisa Yánez (usuario lyanezgu) y compartido con los restantes participantes del grupo Isabela Ignacio (usuario IsaPires1329) y Miguel García (usuario mgarciasanc2021).


# 2. Conjunto de datos elegido

El conjunto de datos elegido por el grupo se llama "Hospital Charges in America" y incluye información que compara las tarifas de los servicios de hospitalizacón en diferentes estados de los EEUU para los 100 principales grupos de diagnósticos. 

**Link del data set:** <https://www.kaggle.com/dhirajnirne/hospital-charges-in-america>.

## 2.1. Paquetes

```{r librerias, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
library(formatR)
library(readr)
library(ggplot2)
library(GGally)
library(dplyr)
library(tidyr)
library(missForest)
library(VIM)
library(formattable)
library(usmap)
library(cowplot)
library(corrplot)
```

## 2.2. Cargar los datos

El conjunto de datos "Hospital Charges in America" contiene 12 columnas y 163.065 filas, y lo obtenemos en formato .csv. 
Inicialmente se han guardado los datos en un data frame llamado "hospital_charges" y se ha realizado un estudio inicial sobre su contenido utilizando la función head y summary.

```{r cargas datos, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
hospital_charges <- read_csv("notebooks/hospital-charges.csv")
hospital_charges
head(hospital_charges)
summary(hospital_charges)
```
##  2.3. Cambiar los nombres de las columnas

Se ha decidido realizar un cambio en el nombre de las variables que aparecen en las columnas de los datos para así seguir un mismo patrón y a al vez evitar tener espacios que nos pueden llegar a dar problemas a futuro.


```{r cambiar columnas 1, include=TRUE, message=FALSE, warning = FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
names(hospital_charges) <- c('drg_def', 'prov_id', 'prov_name', 'prov_address', 'prov_city', 'prov_state', 'prov_zip','hospital_ref', 'total_discharges','mean_covered_charges', 'mean_total_payments', 'mean_medicare_payments')
                    
head(hospital_charges)
```

## 2.4. Cambio de tipo de variable

Se ha decidido eliminar el símbolo de moneda de dólar de las últimas tres columnas, transformando las columnas a tipo numérico.

```{r cambiar dolares, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
hospital_charges$mean_covered_charges = as.numeric(gsub("\\$","",hospital_charges$mean_covered_charges))

hospital_charges$mean_total_payments = as.numeric(gsub("\\$","",hospital_charges$mean_total_payments))

hospital_charges$mean_medicare_payments = as.numeric(gsub("\\$","",hospital_charges$mean_medicare_payments))

hospital_charges$prov_zip = as.factor(hospital_charges$prov_zip)

hospital_charges$prov_id = as.factor(hospital_charges$prov_id)

head(hospital_charges)

str(hospital_charges)
```

# 3. Detección, tratamiento e imputación de datos faltantes

A través de la función summary empezamos comprobando que no hay datos faltantes en el data set. Por ello el grupo ha tenido que añadirlos manualmente para aproximarnos a un caso más real donde lo normal es encontrarlos y tener que lidiar con ellos. Los datos faltantes han sido imputados exclusivamente en las columnas que no van a servir de análisis principal para este estudio, para así intentar que la predicción que hagamos sea lo más precisa posible.

Utilizamos la librería missForest y generamos una semilla para que el resultado sea siempre el mismo.

```{r df, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
hospital_charges
set.seed(101)
hospital_charges <-bind_cols(hospital_charges[c(1,2,3,4,5,6,7,8,11,12)],
                             missForest::prodNA(hospital_charges[c(-1,-2,-3,-4,-5,-6,-7,-8,-11,-12)],noNA=0.1))
hospital_charges
```

Haciendo uso de la librería VIM, analizamos un poco la estructura que tienen nuestros datos faltantes dentro de nuestra data set para ver y entender como se distribuyen.

```{r dfdos, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(aggr(hospital_charges,numbers=T,sortVar=T))

#referencia https://rpubs.com/sediaz/na_aggr
```

# 4. Partición del conjunto de datos: data set training y data set test

Una vez vistos por encima la estructura general de los datos, y habiendo añadido los datos faltantes que nos hacian falta, pasamos a dividir el conjunto de datos en dos, para diferenciar los que usaremos de entrenamiento de los que usaremos de test (viendo la cantidad de datos de la que disponemos, la distribución elegida ha sido: 20% test y 80% training). Establecemos una semilla que nos guarde de forma permanente la división que hacemos, para que la división de los datos sea siempre la misma.

Guardamos además la partición de datos de test para ser utilizada a futuro para la validación del modelo final, y pasamos a trabajar de aquí en adelante con la partición de training.

```{r p, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(101)
sample <- sample.int(n=nrow(hospital_charges), size=floor(.80*nrow(hospital_charges)), replace = F)
train <- hospital_charges[sample,]
test <- hospital_charges[-sample,]

train
test
```


# 5. Imputación de datos faltantes

```{r imputacion, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train$mean_covered_charges[is.na(train$mean_covered_charges)]<-mean(train$mean_covered_charges,na.rm = TRUE)

train$total_discharges[is.na(train$total_discharges)]<-mean(train$total_discharges,na.rm = TRUE)
```
Reemplazamos los valores faltantes de las columnas según los valores medios de las mismas.


# 6. EDA - Análisis exploratorio de datos


## 6.1. Definición de las variables que componen los datos de estudio

Empezando ya el análsis en profundidad del conjunto de datos que tenemos, vemos que las 12 variables que componen los datos pueden ser descritas como:

* **DRG Definition:** Grupo relativo a un diagnostico. 
Los grupos de diagnóstico relacionado (DRG) se utilizan para clasificar la gravedad de la enfermedad en las visitas hospitalarias de pacientes hospitalizados, el riesgo de mortalidad, el pronóstico, la dificultad del tratamiento, la necesidad de intervención y la intensidad de los recursos que necesitan. El sistema DRG fue desarrollado en la Universidad de Yale en la década de 1970 para la clasificación estadística de casos hospitalarios. Realmente la variable DRG es relativa al código y la descripción que identifican el MS-DRG. Los MS-DRG son un sistema de clasificación que agrupa condiciones clínicas similares (diagnósticos) y los procedimientos proporcionados por el hospital durante la estancia. El sistema de Medicare (Sistema de Seguridad Social en EEUU) los utiliza para determinar los reembolsos para hospitales, centros de enfermería especializada y hospicios. Una estadía en el hospital puede variar de un día a 100 días. Los MS-DRG más caros tienen las estadías promedio más largas. El establecimiento del cada DRG se establece según las condiciones clínicas del paciente, necesidad de cantidades similares de recursos para pacientes hospitalizados y sexo y edad del paciente. Para ello se utiliza el sistema de DRG llamado "Medicare Severity DRGs (MS-DRGs)" para reflejar en mejor manera la severidad de la enfermedad del paciente y su consumo de recursos para su recuperación. Para clasificar el nivel de severidad de un paciente dentro del sistema "MS-DRGs" hay códigos secundarios de diagnóstico:
    * MCC: Major Complication/Comorbidity -> El nivel más alto de severidad.
    * CC: Complication/Comorbidity -> El siguiente nivel de severidad.
    * Non-CC: Non-Complication/Comorbidity -> Este nivel no supone una gran severidad en la enfermedad ni un gran gasto de recursos;
    
* **Provider ID:** ID o número identificativo de referencia del hospital;

* **Provider Name:** Nombre del hospital;

* **Provider Street Address:** Dirección postal donde se ubica el hospital;

* **Provider City:** Ciudad donde se ubica el hospital;

* **Provider State:** Estado federal de EEUU donde se ubica el hospital;

* **Provider Zip Code:** Código postal donde se ubica el hospital;

* **Hospital Referral Region Description:** Delinación geográfica específica creada por la organización norteamericana "Dartmouth Atlas of Health Care", para estudiar los mercados vinculados al sector salud en EEUU;

* **Total Discharges:** Número de personas dadas de alta;

* **Average Covered Charges:** Gastos medios del hospital por los servicios cubiertos por la seguridad social para todas las altas del grupo relacionado con el diagnóstico. 
Por lo tanto cargo promedio según grupo de diagnóstico DRG establecido. Los pacientes que tienen características clínicas similares y costos de tratamiento similares se asignan a un Grupo de Diagnóstico Relacionado (DRG). El DRG está vinculado a un monto de pago fijo basado en el costo promedio del tratamiento de los pacientes del grupo.La asignación de DRG se basa en el diagnóstico del paciente, los procedimientos recibidos, la edad y otra información. Por lo tanto esta variable contiene el cargo promedio por cada DRG proporcionado por el hospital. Sus cargos promedio podrían ser más o menos dependiendo de las necesidades específicas de su paciente y los servicios prestados.E  sto es lo que el hospital cobra en la factura final del hospital y es equivalente al "sticker price". Este es en gran medida un número irrelevante, ya que no importa lo que cobren los diferentes hospitales, a todos se les pagará la misma cantidad de Medicare por cualquier DRG dado. Prácticamente nadie paga el "stiker price" en un hospital. Cuando un paciente ha sido admitido como hospitalizado en un hospital, ese hospital asigna un DRG cuando este paciente es dado de alta, basándolo en la atención que necesitaba durante su estadía en el hospital. Al hospital se le paga una cantidad fija por ese DRG, independientemente de cuánto dinero realmente gaste en su tratamiento. Si un hospital puede tratar a un paciente de forma efectiva por menos dinero del que Medicare paga por su DRG, entonces el hospital gana dinero con esa hospitalización. Si el hospital gasta más dinero cuidando del paciente de lo que Medicare le da para su DRG, entonces el hospital pierde dinero en esa hospitalización;

* **Average Medicare Payments:**Importe medio cubierto por la Seguridad Social de EEUU. Esto es lo que Medicare paga al hospital por ese DRG;

* **Average Total Payments:** Importe medio total a pagar por persona. 
Esto es lo que realmente se le paga al hospital e incluye lo que paga Medicare más los copagos que paga el paciente más cualquier cosa que pague el seguro secundario (seguro privado).



## 6.2. Definición de objetivos

El objetivo final del proyecto es llegar a un modelo que permita recomendar cual es el hospital o grupo de hospitales óptimo que debe elegir un paciente enfermo en EEUU, en base a la posible enfermedad que le van a diagnosticar, su localización geográfica y los costes que su caso clínico puede llegar a tener en base al sistema sanitario estadounidense.


Para esta primera entrega, el objetivo es realizar el tratamiento de datos adecuado y seleccionar las mejores variables que servirán para llegar al modelo de Machine Learning deseado. Se realizará de la misma manera un ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple, en base a las variables que mejor expliquen los datos y evaluando si se trata de un modelo correcto para nuestros datos o no.


## 6.3. Transformaciones de variables cuantitativas y procesado de variables cualitativas

### 6.3.1. División de la columna drg_def

Realizamos una división de la columna "drg_ref". Separamos la columna en dos diferenciando entre código de la enfermedad y descripción de la enfermedad. Nos servirá a futuro para simplificar el análisis y visualización de los datos de interés.

```{r, message=FALSE, warning=FALSE, include=TRUE}
train <-train %>% 
  separate(data = ., col = drg_def, 
       into = c("codigo_enf", "desc_enf"), sep = "-")

train$codigo_enf <- as.factor(train$codigo_enf)

train

str(train)
```


### 6.3.2. Creando columna nueva relativa a los copagos que deben realizar los pacientes: mean_total_payments - mean_medicare_payments

Nueva variable representativa del valor de los copagos que debe realizar el paciente o su seguro privado (en caso de contar con uno), para completar, junto a lo que cubre el Estado con el Medicare, el coste total de la intervención hospitalaria.

```{r nueva variable, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
train <- train %>% mutate(copagos = mean_total_payments - mean_medicare_payments)
train
```

### 6.3.3. Creando columna nueva relativa a la tasa de cobertura de la Seguridad Social estadounidense: mean_medicare_payments/mean_total_payments

Nueva variable representativa de la tasa de cobertura que ofrece el sistema de salud de la Seguridad Social americana según el hospital, el grupo de diagnóstico y la gravedad del paciente. Nos ayudamos para ello de la librería formattable, obteniendo resultados en forma de porcentaje de cobertura sobre el total a pagar al hospital.

```{r nueva variabledos, message=FALSE, warning=FALSE, include=TRUE}
train <- train %>% mutate(cobertura = percent(mean_medicare_payments/mean_total_payments))
train
```

### 6.3.4. Creando columna nueva para uso en variables categóricas: Media por Estado según mean_total_payments = mean_total_state

```{r}
train <- train %>% group_by(prov_state) %>% 
  mutate(mean_total_state=mean(mean_total_payments))

train
```

### 6.3.5. Creando columna nueva para uso en variables categóricas: Media por enfermedad según mean_total_payments = mean_total_enf

```{r}
train <- train %>% group_by(codigo_enf) %>% 
  mutate(mean_total_enf=mean(mean_total_payments))
train
summary(train)
```

### 6.3.6. Variable categórica dummy: categoria_state -> niveles alto, medio y bajo

```{r}
#nueva variable agrupando estados por media de copagos
train<-train %>%
    mutate(categoria_state = case_when(mean_total_state >= 12000  ~ 'High',
                                  mean_total_state >= 8500 ~ 'Mid',
                                  TRUE ~ 'Low'))
train

ggplot(train)+geom_bar(aes(x=categoria_state))
```

### 6.3.7. Variable categórica dummy: categoria_enf -> niveles alto, medio y bajo
```{r}
#nueva variable agrupando enfermedades por media de copagos
train<-train %>%
    mutate(categoria_enf = case_when(mean_total_enf >= 13000 ~ 'High',
                                  mean_total_enf >= 5500 ~ 'Mid',
                                  TRUE ~ 'Low'))
train

ggplot(train)+geom_bar(aes(x=categoria_enf))
```

```{r}
res <- model.matrix(~categoria_state, data = train)
head(res[, -1])
```
## 6.4. Análisis exhaustivo de los datos críticos para el estudio

### 6.4.1. Gráfico EEUU: valor de los copagos por Estados

```{r test mapa, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Haciendo la media de lo que cobra el hospital por estado

region_geog <- train %>% group_by(prov_state) %>% summarise (mean_total_price = mean(copagos))
region_geog

#Libreria usmap tiene el mapa de EEUU por estado
library(usmap)

statepop #en libreria usmap hay un dataframe que es la populacion para cada estado 
#(siglas -abbr ) y nos interesa agrupar a este data frame la columna mean_total_payments

names(statepop) <- c('fips','prov_state','full','pop_2015') #cambiamos el nombre de la 
#columna abbr para prov_state para tenerla igual en statepop y region_geog

statepop2 <- statepop %>% left_join(region_geog, by='prov_state') #juntamos region_geog y statepop

plot_usmap(data = statepop2, values = "mean_total_price", color = "white") + 
  scale_fill_continuous(low='light blue', high ='dark blue',name = "Media Copagos", label = scales::dollar) + 
  theme(legend.position = "right")
```

Los estados americanos más caros para el paciente son Wyoming (copagos medio de 1983 dólares), Utah (copagos medio de 1927 dólares) y Hawái (copagos medio de 1851 dólares) 

Wyoming es el estado menos poblado de EEUU (dos tercios del territorio cubiertos por sierras y montañas), los componentes de su economia difieren significativamente de los otros estados (minería y turismo) y el gobierno es dueño de 50% de sus tierras.


### 6.4.2. Gráfico EEUU: valor de los Costes médicos por Estados

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Haciendo la media de lo que cobra el hospital por estado

region_geog_2 <- train %>% group_by(prov_state) %>% summarise (mean_total_cost = mean(mean_total_payments))
region_geog_2

#Libreria usmap tiene el mapa de EEUU por estado
library(usmap)

statepop #en libreria usmap hay un dataframe que es la populacion para cada estado 
#(siglas -abbr ) y nos interesa agrupar a este data frame la columna mean_total_payments

names(statepop) <- c('fips','prov_state','full','pop_2015') #cambiamos el nombre de la 
#columna abbr para prov_state para tenerla igual en statepop y region_geog

statepop3 <- statepop %>% left_join(region_geog_2, by='prov_state') #juntamos region_geog y statepop

plot_usmap(data = statepop3, values = "mean_total_cost", color = "white") + 
  scale_fill_continuous(low='light green', high ='dark green',name = "Media Costes totales hospital", label = scales::dollar) + 
  theme(legend.position = "right")
```


### 6.4.3. Top 10 enfermedades más comunes detectadas

```{r, message=FALSE, warning=FALSE, include=TRUE}
d2 <- train %>%
  count(codigo_enf) %>%
  top_n(10) %>%
  arrange(n, codigo_enf) %>%
  mutate(codigo_enf = factor(codigo_enf, levels = unique(codigo_enf)))

train %>%
  filter(codigo_enf %in% d2$codigo_enf) %>%
  mutate(codigo_enf = factor(codigo_enf, levels = levels(d2$codigo_enf))) %>%
  ggplot(aes(x = codigo_enf, fill=desc_enf)) + geom_bar() + coord_flip() + 
theme_bw(base_size=9) + xlab("Código enfermedad") + 
    ylab("Frecuencia") +
    ggtitle("10 enfermedadas más comunes")
```

El grupo DRG de mayor frecuencia es "194 - Pneumonia y Pleuresía con complicaciones/comorbilidades" con 2.424 casos. En segundo y tercer lugar tenemos las "690 - Infecciones de las vías urinarias" (2.400 casos) y "392 -Esofagitis, Gastroenteritis y Enfermedades digestivas con " (2.368 casos) con o sin complicaciones.


### 6.4.4. Top 10 enfermedades más caras 

```{r, message=FALSE, warning=FALSE, include=TRUE}

d3 <- train %>%
  group_by(codigo_enf) %>% summarise(mean=mean(mean_total_payments)) %>% arrange(desc(mean))

top_10_caras <- head(d3,10)
top_10_caras


ggplot(data=top_10_caras, mapping = aes(x = reorder(codigo_enf,-mean),mean)) + geom_bar(stat = "identity", aes(fill=mean)) + theme_bw(base_size=9) + ylab("Media Total Payments") + xlab("Codigo enfermedad") + ggtitle("10 enfermedadas más caras") + scale_y_continuous(label = scales::dollar) + scale_fill_gradient(low="light blue", high="dodgerblue4")


```

El grupo DRG más caro es "870 - Septicemia y sepsis grave con periodo de hospitalización superior a 96 horas". Una septicemia occure cuando el sistema inmunitario se descontrola y ataca a sus proprios órganocs y tejidos. Es la complicación de una infección, siendo una urgencia médica que requiere tratamiento inmediato. El coste media del tratamiento en los EEUU es de 44.467 dólares. 

El segundo y tercer grupo DRG más caros son las "853 - Infecciones y enfermedades parasitarias" (coste médio de 40.296 dólares) y "207- Enfermedades respiratorias que requieren ventilación respiratória por más de 96 horas consecutivas (coste médio de 38372.14 dólares).	

### 6.4.5. Gráfico de calor - ratio de cobertura por Estado para las 10 enfermedades más caras

```{r, message=FALSE, warning=FALSE, include=TRUE}
test <- top_10_caras %>% inner_join(train)
test
ggplot(test, aes(codigo_enf,prov_state, fill=cobertura))+geom_tile() + theme_bw(base_size=7) + scale_fill_gradient(low = "white", high = "purple")


```
De manera general se puede decir que la tasa de cobertura de las top 10 enfermedades más caras es, en todos los estados de Estados Unidos, superior a 80% (colores morado escuro predominante en casi todo el gráfico).

La tasa de cobertura para la enfermedad Septicemia es en media, para todos los estados, de 95%, siendo entonces la enfermedad más cara para el sistema público, pero con gran cobertura y pocos copagos al paciente. Lo mismo se puede observar para las Enfermedades Parasitárias (94%) y Enfermedades Respiratória (93%).

En el de Wyoming, el estado donde se hay que pagar las mayores cifras de copagos, no han sido registrados casos de Septicemia o Enfermedades Respiratórias, mientras la tasa de cobertura para Enfermedades Parasitárias es de 82%.


### 6.4.6. Correlación entre variables

```{r, message=FALSE, warning=FALSE, include=TRUE}
library(PerformanceAnalytics)

cor(x=train$mean_total_payments, y=train$mean_medicare_payments)
```

```{r}
with(train, plot(x=mean_total_payments, y=mean_medicare_payments, pch=20, col='blue',
                 xlab='mean total payments', las=1,
                 ylab='mean_medicare_payments'))
```


```{r, message=FALSE, warning=FALSE, include=TRUE}
library(dplyr)
library(ggplot2)
train %>% ggplot(aes(mean_total_payments, mean_medicare_payments)) + 
  geom_point(alpha=0.2, colour="green") + 
  geom_smooth(formula= 'y ~ x',method = 'lm') + 
  labs(title='Relacion entre variables total payments y medicare payments', 
       x='mean total payments',
       y='mean medicare payments`')

```


### 6.4.7. Análisis de la distribución de las variables

```{r, message=FALSE, warning=FALSE, include=TRUE}
# ver si el mean total payments sigue una normal 
train%>%
  filter(mean_total_payments<100000 ) %>%
  ggplot(aes(x=mean_total_payments))+ geom_histogram()
```

```{r, message=FALSE, warning=FALSE, include=TRUE}
# ver si el mean total payments sigue una normal 
train%>%
  filter(mean_total_payments<100000 ) %>%
  ggplot(aes(x=log10(mean_total_payments)))+ geom_histogram()
```



```{r}
# ver si el mean total payments sigue una normal 
train%>%
  filter(mean_medicare_payments<100000 ) %>%
  ggplot(aes(x=mean_medicare_payments))+ geom_histogram()
```

```{r,message=FALSE, warning=FALSE, include=TRUE}
# ver si el mean total payments sigue una normal 
train%>%
  filter(mean_medicare_payments<100000 ) %>%
  ggplot(aes(x=log10(mean_medicare_payments)))+ geom_histogram()


```


```{r,message=FALSE, warning=FALSE, include=TRUE}
# ver si el mean total payments sigue una normal 
train%>%
  filter(mean_medicare_payments<100000 ) %>%
  ggplot(aes(x=copagos))+ geom_histogram()


```


```{r,message=FALSE, warning=FALSE, include=TRUE}
# ver si el mean total payments sigue una normal 
train%>%
  filter(mean_medicare_payments<100000 ) %>%
  ggplot(aes(x=log10(copagos)))+ geom_histogram()


```

```{r,message=FALSE, warning=FALSE, include=TRUE}
#train %>% select(1:14) %>%
#  na.omit() %>%
#  ggpairs(columns = 1:13, ggplot2::aes(colour=group),cardinality_threshold=50000)

```

### 6.4.8. Boxplot - análisis de la variables de relevancia y de los atípicos observados

```{r, message=FALSE, warning=FALSE, include=TRUE}
train_num <- Filter(is.numeric, train)
train_num
```

```{r, message=FALSE, warning=FALSE, include=TRUE}
p1 <- ggplot (train_num, aes(y= train_num$mean_total_payments)) + geom_boxplot(fill = "red") + scale_y_continuous(name = "dólares", labels = scales::dollar) + xlab("mean_total_payments") + ggtitle("Boxplot: mean_total_payments")

p11 <- ggplot (train_num, aes(y= log10(train_num$mean_total_payments))) + geom_boxplot(fill = "red") + scale_y_continuous(name = " Log dólares", labels = scales::dollar) + xlab("mean_total_payments") + ggtitle("Boxplot: Log mean_total_payments")

plot_grid(p1, p11)
mean(train_num$mean_total_payments)

```

```{r, message=FALSE, warning=FALSE, include=TRUE}
p2 <- ggplot (train_num, aes(y=train_num$mean_medicare_payments)) + geom_boxplot(fill = "blue") + scale_y_continuous(name = "dólares", labels = scales::dollar) + xlab("mean_medicare_payments") + ggtitle("Boxplot: mean_medicare_payments")

p22 <- ggplot (train_num, aes(y= log10(train_num$mean_medicare_payments))) + geom_boxplot(fill = "blue") + scale_y_continuous(name = "Log dólares", labels = scales::dollar) + xlab("mean_medicare_payments") + ggtitle("Boxplot: Log mean_medicare_payments")

plot_grid(p2, p22)
mean(train_num$mean_medicare_payments)
```

```{r, message=FALSE, warning=FALSE, include=TRUE}
p3 <- ggplot (train_num, aes(y=train_num$copagos)) + geom_boxplot(fill = "yellow") + scale_y_continuous(name = "dólares", labels = scales::dollar) + xlab("copagos") + ggtitle("Boxplot: copagos")

p33 <- ggplot (train_num, aes(y=log10(train_num$copagos))) + geom_boxplot(fill = "yellow") + scale_y_continuous(name = "Log dólares", labels = scales::dollar) + xlab("copagos") + ggtitle("Boxplot: Log copagos")

plot_grid(p3, p33)
mean(train_num$copagos)
```

```{r, message=FALSE, warning=FALSE, include=TRUE}
p4 <- ggplot (train_num, aes(y=train_num$cobertura)) + geom_boxplot(fill = "green") + scale_y_continuous(name = "% cobertura") + xlab("cobertura") + ggtitle("Boxplot: cobertura")

p4
mean(train_num$cobertura)

```

### 6.4.9. Análisis de correlación entre variables
```{r}
res <- cor(train_num)
round(res, 2)

corrplot(res, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```
```{r}

#ggpairs(train_num, lower = list(continuous = "smooth"), 
#        diag = list(continuous = "bar"), axisLabels = "none", cardinality_threshold=5000)

#pairs(x = train_num)
```

```{r}
ggplot(data = train, mapping=aes(x = categoria_state, y = log10(copagos), color=categoria_state)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")

```
# 7. Regresion lineal multiple

```{r}
library(MASS)
#attach(train)
```
## 7.1. Seleccion de variables para modelo de regresión

Para la seleccion de variables para nuestro modelo usaremos la técnica forward stepwise 

```{r}
modelo_1= lm(copagos~categoria_state+categoria_enf+log(cobertura),data=train)
#coef(modelo)
summary(modelo_1)
```

```{r}
modelo_2= lm(copagos~categoria_state+categoria_enf+cobertura+mean_covered_charges,data=train)
#coef(modelo)
summary(modelo_2)
```
```{r}
modelo_3= lm(copagos~categoria_state+categoria_enf+
               mean_medicare_payments,data=train)
#coef(modelo)
summary(modelo_3)
```

```{r}
modelo_4= lm(copagos~categoria_state+categoria_enf+cobertura+
               mean_total_payments+total_discharges+mean_covered_charges,data=train)
#coef(modelo)
summary(modelo_4)
```


```{r}
library(ggfortify)
autoplot(modelo_2)
```

```{r}
#medimos independencia entre los residuos
#entonces no rechazamos la  hipotesis nula y podemos asumir que los residuos no presentan autcorrelacion 
library(lmtest)
dwtest(modelo_2)
```

```{r}
#scale-location-homocedasticidad
#rechazamos la hipotesis nula que la varianza de los errores ees constante
bptest(modelo_2)
```
En el gráfico de Residuos vs. Ajustes se observa que la media de los residuos es cercana a cero, luego la linealidad del modelo no se viola. Sin embargo, hay claro patrón de embudo, lo que indica que se viola el principio de homocedasticidad del modelo. Es decir, la varianza de los residuos no es constante y el ajuste del modelo no es adecuado. También se señalan algunos puntos candidatos a ser outliers.

Con el Q-Q plot vemos que los residuos no siguen una distribución normal en las colas. Por tanto, no se puede asumir que los estimadores de los coeficientes tengan una distribución normal. Del gráfico de residuals vs leverage, observamos que hay puntos con alto leverage pero ninguno cae fuera de los límites de la distancia de Cook.


